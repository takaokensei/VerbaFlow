{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VerbaFlow - Experimenta√ß√£o com Agentes\n",
        "\n",
        "Este notebook demonstra o uso dos agentes CrewAI do VerbaFlow para classifica√ß√£o e enriquecimento de textos.\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "Testar o sistema multi-agente sem a interface Streamlit, permitindo experimenta√ß√£o direta com os componentes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ M√≥dulos importados com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Importa√ß√µes necess√°rias\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Carregar vari√°veis de ambiente do arquivo .env\n",
        "load_dotenv()\n",
        "\n",
        "# Adicionar diret√≥rio raiz ao path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Importar m√≥dulos do VerbaFlow\n",
        "from src.utils import fetch_newsgroups_samples, clean_text, extract_ground_truth_from_filename, get_text_from_file\n",
        "from src.agents import get_llm, create_analyst_agent, create_researcher_agent, create_editor_agent\n",
        "from src.tasks import create_classification_task, create_enrichment_task, create_reporting_task\n",
        "from crewai import Crew, Process\n",
        "\n",
        "print(\"‚úÖ M√≥dulos importados com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configura√ß√£o de API Keys\n",
        "\n",
        "Configure suas chaves de API nas vari√°veis de ambiente antes de executar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurar API Keys\n",
        "# IMPORTANTE: Substitua pelos seus valores reais ou use vari√°veis de ambiente\n",
        "os.environ[\"GROQ_API_KEY\"] = \"sua-groq-api-key-aqui\"\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"sua-tavily-api-key-aqui\"\n",
        "\n",
        "print(\"‚ö†Ô∏è Lembre-se de configurar suas API keys antes de executar!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carregar Dados de Exemplo\n",
        "\n",
        "Vamos carregar uma amostra do dataset 20 Newsgroups para testar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar uma amostra do dataset\n",
        "# Se j√° tiver amostras salvas, pode usar diretamente\n",
        "sample_file = \"data/samples/rec.sport.hockey___1.txt\"\n",
        "\n",
        "# Se n√£o existir, vamos gerar uma amostra\n",
        "if not os.path.exists(sample_file):\n",
        "    print(\"Gerando amostras do dataset 20 Newsgroups...\")\n",
        "    samples = fetch_newsgroups_samples(num_samples=1)\n",
        "    sample_file = samples[0] if samples else None\n",
        "\n",
        "if sample_file and os.path.exists(sample_file):\n",
        "    # Carregar texto\n",
        "    raw_text = get_text_from_file(sample_file)\n",
        "    ground_truth = extract_ground_truth_from_filename(sample_file)\n",
        "    \n",
        "    print(f\"üìÑ Arquivo: {os.path.basename(sample_file)}\")\n",
        "    print(f\"üè∑Ô∏è Categoria Real: {ground_truth}\")\n",
        "    print(f\"\\nüìù Texto (primeiros 500 caracteres):\\n{raw_text[:500]}...\")\n",
        "else:\n",
        "    print(\"‚ùå Erro ao carregar amostra\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pr√©-processamento do Texto\n",
        "\n",
        "Limpar e preparar o texto para classifica√ß√£o.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Limpar texto\n",
        "cleaned_text = clean_text(raw_text)\n",
        "print(f\"‚úÖ Texto limpo ({len(cleaned_text)} caracteres)\")\n",
        "print(f\"\\nPrimeiros 300 caracteres do texto limpo:\\n{cleaned_text[:300]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Criar Agentes\n",
        "\n",
        "Inicializar os tr√™s agentes do sistema VerbaFlow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar LLM\n",
        "llm = get_llm()\n",
        "\n",
        "# Criar agentes\n",
        "analyst = create_analyst_agent(llm)\n",
        "researcher = create_researcher_agent(llm)\n",
        "editor = create_editor_agent(llm)\n",
        "\n",
        "print(\"‚úÖ Agentes criados com sucesso!\")\n",
        "print(f\"  - {analyst.role}\")\n",
        "print(f\"  - {researcher.role}\")\n",
        "print(f\"  - {editor.role}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Criar Tasks\n",
        "\n",
        "Definir as tr√™s tasks sequenciais do pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar tasks\n",
        "task1 = create_classification_task(analyst, cleaned_text)\n",
        "task2 = create_enrichment_task(researcher, task1)\n",
        "task3 = create_reporting_task(editor, task1, task2)\n",
        "\n",
        "print(\"‚úÖ Tasks criadas com sucesso!\")\n",
        "print(f\"  - Task 1: Classifica√ß√£o\")\n",
        "print(f\"  - Task 2: Enriquecimento (depende de Task 1)\")\n",
        "print(f\"  - Task 3: Relat√≥rio (depende de Task 1 e 2)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Executar Crew\n",
        "\n",
        "Executar o pipeline completo com os agentes trabalhando em sequ√™ncia.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir OPENAI_API_KEY como dummy para evitar erro de importa√ß√£o\n",
        "# (CrewAI tenta importar OpenAI mesmo quando usamos LLM customizado)\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"dummy-key-to-prevent-openai-import-error\"\n",
        "\n",
        "# Definir OPENAI_API_KEY como dummy para evitar erro de importa√ß√£o\n",
        "# (CrewAI tenta importar OpenAI mesmo quando usamos LLM customizado)\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = \"dummy-key-to-prevent-openai-import-error\"\n",
        "\n",
        "# Criar crew com LLM configurado explicitamente com LLM configurado explicitamente\n",
        "crew = Crew(\n",
        "    agents=[analyst, researcher, editor],\n",
        "    tasks=[task1, task2, task3],\n",
        "    process=Process.sequential,\n",
        "    verbose=True,\n",
        "    llm=llm  # Especificar LLM explicitamente\n",
        ")\n",
        "\n",
        "print(\"üöÄ Executando VerbaFlow...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Executar\n",
        "result = crew.kickoff()\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"‚úÖ Execu√ß√£o conclu√≠da!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resultados\n",
        "\n",
        "Exibir o resultado final e validar a classifica√ß√£o.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Extrair categoria prevista\n",
        "predicted_category = \"\"\n",
        "category_match = re.search(r'Category:\\s*([^\\n]+)', str(result), re.IGNORECASE)\n",
        "if category_match:\n",
        "    predicted_category = category_match.group(1).strip()\n",
        "\n",
        "# Comparar com ground truth\n",
        "is_correct = predicted_category.lower() == ground_truth.lower()\n",
        "\n",
        "print(\"üìä Resultados da Valida√ß√£o\")\n",
        "print(f\"  Categoria Real: {ground_truth}\")\n",
        "print(f\"  Categoria Prevista: {predicted_category if predicted_category else 'N√£o encontrada'}\")\n",
        "print(f\"  Status: {'‚úÖ CORRETO' if is_correct else '‚ùå INCORRETO'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Relat√≥rio Completo\n",
        "\n",
        "Exibir o relat√≥rio enriquecido completo gerado pelo Editor Chefe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exibir relat√≥rio completo\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"üìã RELAT√ìRIO ENRIQUECIDO COMPLETO\")\n",
        "print(\"=\" * 50 + \"\\n\")\n",
        "print(result)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
