# ğŸ§  VerbaFlow

![Python](https://img.shields.io/badge/python-3.12-blue.svg)
![CrewAI](https://img.shields.io/badge/AI-CrewAI-orange)
![Streamlit](https://img.shields.io/badge/frontend-Streamlit-red)
![License](https://img.shields.io/badge/license-MIT-green)

> **Sistema Multi-Agente para ClassificaÃ§Ã£o e Enriquecimento Contextual de Textos.**
> *Projeto Capstone desenvolvido para o MÃ³dulo 15 da FormaÃ§Ã£o em InteligÃªncia Artificial (DSA).*

---

## ğŸ“– Sobre o Projeto

**VerbaFlow** Ã© uma aplicaÃ§Ã£o que demonstra a evoluÃ§Ã£o do Processamento de Linguagem Natural (NLP) saindo de modelos estÃ¡ticos para sistemas dinÃ¢micos baseados em agentes.

Utilizando o paradigma **ReAct (Reason + Act)**, o sistema nÃ£o apenas classifica uma notÃ­cia (como modelos tradicionais), mas "entende" o conteÃºdo, busca validaÃ§Ã£o externa na web em tempo real e gera um relatÃ³rio enriquecido.

### âœ¨ Diferenciais
* **OrquestraÃ§Ã£o de Agentes:** 3 agentes especializados trabalhando em cadeia.
* **Enriquecimento Web:** Uso da API Tavily para buscar fatos atuais sobre textos antigos (anos 90).
* **ValidaÃ§Ã£o AutomÃ¡tica:** ComparaÃ§Ã£o em tempo real entre a *PrediÃ§Ã£o do Agente* e o *Ground Truth* do dataset.
* **Interface Interativa:** UI amigÃ¡vel construÃ­da com Streamlit.

---

## ğŸ—ï¸ Arquitetura do Sistema

O fluxo de trabalho segue um pipeline sequencial processado pelo framework **CrewAI**:

```mermaid
graph TD
    A[UsuÃ¡rio / Input] --> B(Agente 1: O Analista);
    B -->|ClassificaÃ§Ã£o & TÃ³pico| C(Agente 2: O Pesquisador);
    C -->|Contexto Web & Fatos| D(Agente 3: O Editor Chefe);
    D -->|RelatÃ³rio Final Markdown| E[Interface Streamlit];
    
    subgraph "ValidaÃ§Ã£o"
    B -.-> V{Comparar com Ground Truth};
    V -->|âœ… ou âŒ| E;
    end
````

### Os Agentes

1.  ğŸ•µï¸ **O Analista:** Especialista em NLP. LÃª o texto bruto e determina a categoria exata (baseado no dataset 20 Newsgroups).
2.  ğŸŒ **O Pesquisador:** Especialista em Fact-Checking. Usa o **Tavily** para buscar o contexto moderno do tÃ³pico identificado.
3.  âœï¸ **O Editor Chefe:** Especialista em sÃ­ntese. Compila a classificaÃ§Ã£o tÃ©cnica e a pesquisa web em um relatÃ³rio executivo em PortuguÃªs.

-----

## ğŸš€ Tecnologias Utilizadas

  * **Core:** Python 3.12 (VersÃ£o estÃ¡vel para CrewAI/Pydantic)
  * **OrquestraÃ§Ã£o:** CrewAI
  * **LLM Engine:** Groq (Modelo: `llama-3.3-70b-versatile`)
  * **Ferramentas (Tools):** Tavily Search API
  * **Interface:** Streamlit
  * **Dados:** Scikit-Learn (20 Newsgroups) & Pandas

-----

## ğŸ“ Estrutura do RepositÃ³rio

```bash
VerbaFlow/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ samples/          # Cache de amostras do 20 Newsgroups (com Ground Truth no nome)
â”‚   â””â”€â”€ raw/              # Dataset customizado (CSV)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents.py         # DefiniÃ§Ã£o dos Agentes (Brain)
â”‚   â”œâ”€â”€ tasks.py          # DefiniÃ§Ã£o das Tarefas (Instructions)
â”‚   â”œâ”€â”€ tools.py          # ConfiguraÃ§Ã£o do Tavily
â”‚   â””â”€â”€ utils.py          # Carregamento e limpeza de dados
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ experimentacao_agentes.ipynb  # Sandbox para testes sem interface
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ GAMMA_SLIDES_PROMPT.md        # Prompt para geraÃ§Ã£o de slides
â”œâ”€â”€ app.py                # AplicaÃ§Ã£o Principal (Entry Point)
â”œâ”€â”€ requirements.txt      # DependÃªncias do projeto
â””â”€â”€ .env.example          # Template de variÃ¡veis de ambiente
```

-----

## âš¡ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### PrÃ©-requisitos

  * Python 3.12+
  * API Key do [Groq](https://groq.com/)
  * API Key do [Tavily](https://tavily.com/)
  * (Opcional) API Key do [Google Gemini](https://ai.google.dev/) para fallback automÃ¡tico

### Passo a Passo

1.  **Clone o repositÃ³rio:**

    ```bash
    git clone [https://github.com/takaokensei/VerbaFlow.git](https://github.com/takaokensei/VerbaFlow.git)
    cd VerbaFlow
    ```

2.  **Crie o ambiente virtual:**

    ```bash
    python -m venv venv
    # Windows
    venv\Scripts\activate
    # Linux/Mac
    source venv/bin/activate
    ```

3.  **Instale as dependÃªncias:**

    ```bash
    pip install -r requirements.txt
    ```

4.  **Configure as Chaves de API:**
     
     **IMPORTANTE:** Crie um arquivo `.env` na raiz do projeto (copie do `.env.example`):
     
     ```bash
     # Windows (PowerShell)
     Copy-Item .env.example .env
     
     # Linux/Mac
     cp .env.example .env
     ```
     
     Depois, edite o arquivo `.env` e insira suas chaves reais:
     
     ```env
     GROQ_API_KEY=sua_chave_groq_aqui
     TAVILY_API_KEY=sua_chave_tavily_aqui
     GOOGLE_API_KEY=sua_chave_gemini_aqui  # Opcional: para fallback automÃ¡tico
     USE_GEMINI_FALLBACK=true              # Opcional: ativar fallback automÃ¡tico
     ```
     
     âš ï¸ **Nota:** O arquivo `.env` estÃ¡ no `.gitignore` e nÃ£o serÃ¡ commitado. O `.env.example` Ã© apenas um template.

6.  **(Opcional) Instale o Provider Nativo do Gemini para Fallback:**
     
     Se vocÃª quiser usar o fallback automÃ¡tico para Gemini quando o Groq atingir o rate limit, instale o provider nativo:
     
     ```bash
     # OpÃ§Ã£o 1: Usando o script fornecido
     python install_gemini_provider.py
     
     # OpÃ§Ã£o 2: InstalaÃ§Ã£o manual
     pip install 'crewai[google-genai]'
     ```
     
     âš ï¸ **Nota:** O provider nativo do Gemini Ã© opcional. Se nÃ£o estiver instalado, o sistema ainda funcionarÃ¡ com Groq, mas o fallback automÃ¡tico para Gemini nÃ£o estarÃ¡ disponÃ­vel.

7.  **Execute a AplicaÃ§Ã£o:**

    ```bash
    streamlit run app.py
    ```

-----

## ğŸ“Š Dados e ValidaÃ§Ã£o

O sistema foi projetado para suportar duas fontes de dados para fins de demonstraÃ§Ã£o acadÃªmica:

1.  **20 Newsgroups:** Dataset canÃ´nico de classificaÃ§Ã£o de textos. O sistema extrai o *Ground Truth* do nome do arquivo (ex: `sci.space___sample1.txt`) e valida se o Agente Analista acertou a previsÃ£o.
2.  **CSV Customizado:** Suporte para carga de dados proprietÃ¡rios via arquivo `data/raw/Base_dados_textos_6_classes.csv`.

-----

## ğŸ‘¤ Autor

**CauÃ£ Vitor F. Silva**

  * *Engenharia ElÃ©trica - UFRN*
  * *Projeto desenvolvido para o MÃ³dulo 15 da Data Science Academy.*

-----

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](https://www.google.com/search?q=LICENSE) para mais detalhes.