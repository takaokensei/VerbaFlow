"""
Aplica√ß√£o Streamlit principal do VerbaFlow.
"""
import os
import re
import streamlit as st
from pathlib import Path
from dotenv import load_dotenv
from crewai import Crew, Process
import sys
from io import StringIO

# Carregar vari√°veis de ambiente do arquivo .env
load_dotenv()

# Importar estilos customizados
from src.styles import inject_custom_css, apply_page_config

# Aplicar configura√ß√£o e estilos
apply_page_config()
inject_custom_css()

from src.utils import (
    fetch_newsgroups_samples,
    clean_text,
    load_custom_csv,
    extract_ground_truth_from_filename,
    get_text_from_file
)
from src.agents import (
    get_llm,
    get_llm_with_fallback,
    create_analyst_agent,
    create_researcher_agent,
    create_editor_agent
)
from src.tasks import (
    create_classification_task,
    create_enrichment_task,
    create_reporting_task
)
from src.config import get_config
from src.models import ClassificationOutput
import json


def extract_category_robust(text: str) -> str:
    """
    Extrai a categoria do output do modelo com parsing robusto.
    Tenta m√∫ltiplos padr√µes regex para encontrar 'Category: <nome>'.
    Tamb√©m procura no relat√≥rio final por "Categoria Identificada:".
    
    Args:
        text: Texto do output do modelo
    
    Returns:
        Categoria extra√≠da ou string vazia
    """
    if not text:
        return ""
    
    # Padr√µes regex para tentar (em ordem de especificidade)
    patterns = [
        r'Category:\s*([^\n\r]+)',  # Padr√£o b√°sico
        r'Category\s*:\s*([^\n\r]+)',  # Com espa√ßos vari√°veis
        r'Categoria\s+Identificada:\s*([^\n\r]+)',  # Do relat√≥rio final
        r'Categoria:\s*([^\n\r]+)',  # Em portugu√™s
        r'Category\s*=\s*([^\n\r]+)',  # Com igual
        r'Final\s+Category:\s*([^\n\r]+)',  # Com prefixo
        r'Classified\s+as:\s*([^\n\r]+)',  # Alternativo
        r'categoria\s+identificada[:\s]+([^\n\r]+)',  # Case insensitive
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
        if match:
            category = match.group(1).strip()
            # Limpar pontua√ß√£o extra no final e aspas
            category = re.sub(r'[.,;:!?"\']+$', '', category)
            category = category.strip('"\'')
            # Verificar se √© uma categoria v√°lida do 20 Newsgroups
            valid_categories = [
                'alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc',
                'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x',
                'misc.forsale', 'rec.autos', 'rec.motorcycles',
                'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt',
                'sci.electronics', 'sci.med', 'sci.space',
                'soc.religion.christian', 'talk.politics.guns',
                'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc'
            ]
            # Verificar se a categoria extra√≠da corresponde a uma v√°lida
            if any(cat.lower() == category.lower() for cat in valid_categories):
                return category
            # Se n√£o corresponder exatamente, retornar mesmo assim (pode ser varia√ß√£o)
            if category:
                return category
    
    return ""


# T√≠tulo principal com estilo centralizado
st.markdown("""
<div class="main-header">
    <h1>VerbaFlow</h1>
    <p>Sistema Multi-Agente para Classifica√ß√£o e Enriquecimento de Textos</p>
</div>
""", unsafe_allow_html=True)

st.markdown("---")

# Sidebar para configura√ß√µes
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    
    # Carregar valores do .env como valores padr√£o
    groq_key_env = os.getenv("GROQ_API_KEY", "")
    tavily_key_env = os.getenv("TAVILY_API_KEY", "")
    
    groq_key = st.text_input(
        "Groq API Key",
        value=groq_key_env if groq_key_env else "",
        type="password",
        help="Chave de API do Groq (obrigat√≥ria). Se deixar vazio, usa o valor do arquivo .env"
    )
    
    tavily_key = st.text_input(
        "Tavily API Key",
        value=tavily_key_env if tavily_key_env else "",
        type="password",
        help="Chave de API do Tavily (obrigat√≥ria para enriquecimento). Se deixar vazio, usa o valor do arquivo .env"
    )
    
    st.markdown("---")
    st.markdown("### ü§ñ Modelo Groq")
    
    # Aviso sobre rate limit
    st.warning("""
    ‚ö†Ô∏è **Limite de Tokens do Groq:**
    
    - **Tier Gratuito:** 100,000 tokens/dia
    - **Recomendado:** `llama-3.1-8b-instant` (consome ~10x menos tokens)
    - **Upgrade:** https://console.groq.com/settings/billing
    
    üí° **Dica:** O modelo `llama-3.1-8b-instant` √© r√°pido, eficiente e tem qualidade excelente para classifica√ß√£o!
    """)
    
    model_choice = st.selectbox(
        "Selecione o modelo:",
        [
            "llama-3.1-8b-instant (Recomendado: Mais r√°pido, menos tokens) ‚≠ê",
            "llama-3.3-70b-versatile (Melhor qualidade, mais tokens)",
            "mixtral-8x7b-32768 (Alternativa)"
        ],
        help="üí° Modelos menores consomem muito menos tokens! Use llama-3.1-8b-instant para evitar rate limits."
    )
    
    # Extrair nome do modelo
    if "llama-3.1-8b" in model_choice:
        selected_model = "llama-3.1-8b-instant"
    elif "llama-3.3-70b" in model_choice:
        selected_model = "llama-3.3-70b-versatile"
    else:
        selected_model = "mixtral-8x7b-32768"
    
    # Salvar API keys nas vari√°veis de ambiente
    # Se o usu√°rio digitou algo, usa isso. Sen√£o, mant√©m o valor do .env
    if groq_key:
        os.environ["GROQ_API_KEY"] = groq_key
    elif groq_key_env:
        os.environ["GROQ_API_KEY"] = groq_key_env
    
    if tavily_key:
        os.environ["TAVILY_API_KEY"] = tavily_key
    elif tavily_key_env:
        os.environ["TAVILY_API_KEY"] = tavily_key_env
    
    os.environ["GROQ_MODEL"] = selected_model
    
    # Mostrar status das chaves
    st.markdown("---")
    st.markdown("### ‚úÖ Status das Configura√ß√µes")
    
    if groq_key_env or groq_key:
        st.success("‚úÖ Groq API Key configurada")
    else:
        st.warning("‚ö†Ô∏è Groq API Key n√£o encontrada")
    
    if tavily_key_env or tavily_key:
        st.success("‚úÖ Tavily API Key configurada")
    else:
        st.info("‚ÑπÔ∏è Tavily API Key opcional (enriquecimento n√£o funcionar√° sem ela)")
    
    
    # Hist√≥rico de execu√ß√µes
    st.markdown("---")
    st.markdown("### üìú Hist√≥rico de Execu√ß√µes")
    
    if 'execution_history' not in st.session_state:
        st.session_state['execution_history'] = []
    
    if st.session_state['execution_history']:
        for i, hist_item in enumerate(reversed(st.session_state['execution_history'][-5:]), 1):
            category = hist_item.get('predicted', hist_item.get('category', 'N/A'))
            timestamp = hist_item.get('timestamp', '')[:16] if hist_item.get('timestamp') else 'Sem data'
            is_correct = hist_item.get('is_correct', hist_item.get('correct', False))
            
            with st.expander(f"Execu√ß√£o {i}: {category} - {timestamp}", expanded=False):
                st.write(f"**Categoria Real:** {hist_item.get('ground_truth', 'N/A')}")
                st.write(f"**Categoria Prevista:** {category}")
                st.write(f"**Status:** {'‚úÖ Correto' if is_correct else '‚ùå Incorreto'}")
                st.write(f"**Provider:** {hist_item.get('llm_provider', 'N/A')}")
                if st.button(f"Ver detalhes completos", key=f"hist_{i}"):
                    st.session_state['view_history_item'] = hist_item
    else:
        st.info("Nenhuma execu√ß√£o ainda. Execute uma classifica√ß√£o para ver o hist√≥rico.")
    
    st.markdown("---")
    st.markdown("### üìä Fonte de Dados")
    
    data_source = st.radio(
        "Selecione a fonte de dados:",
        ["20 Newsgroups (Amostras)", "CSV Customizado (6 Classes)"],
        index=0
    )


# √Årea principal
# Verificar se temos Groq API Key (do .env ou da sidebar)
groq_key_available = os.getenv("GROQ_API_KEY")
if not groq_key_available:
    st.warning("""
    ‚ö†Ô∏è **Groq API Key n√£o encontrada!**
    
    Configure de uma das seguintes formas:
    1. **Arquivo .env:** Adicione `GROQ_API_KEY=sua_chave_aqui` no arquivo `.env`
    2. **Sidebar:** Digite a chave no campo "Groq API Key" na barra lateral
    """)
    st.stop()

# Sele√ß√£o de dados
if data_source == "20 Newsgroups (Amostras)":
    st.subheader("üì∞ Dataset 20 Newsgroups")
    
    if st.button("üîÑ Carregar Amostras Aleat√≥rias"):
        with st.spinner("Baixando amostras do dataset 20 Newsgroups..."):
            try:
                samples = fetch_newsgroups_samples(num_samples=5)
                st.session_state['samples'] = samples
                st.success(f"‚úÖ {len(samples)} amostras carregadas com sucesso!")
            except Exception as e:
                st.error(f"‚ùå Erro ao carregar amostras: {e}")
    
    if 'samples' in st.session_state and st.session_state['samples']:
        sample_files = st.session_state['samples']
        selected_file = st.selectbox(
            "Selecione uma amostra:",
            options=sample_files,
            format_func=lambda x: os.path.basename(x)
        )
        
        if selected_file:
            # Carregar texto
            raw_text = get_text_from_file(selected_file)
            ground_truth = extract_ground_truth_from_filename(selected_file)
            
            # Exibir texto e ground truth
            st.markdown("### üìÑ Texto Original")
            st.text_area("Texto Original", raw_text, height=200, disabled=True, key="raw_text_display", label_visibility="visible")
            
            st.markdown(f"### üè∑Ô∏è Categoria Real (Ground Truth)")
            st.info(f"**{ground_truth}**")
            
            # Executar VerbaFlow
            if st.button("üöÄ Executar VerbaFlow", type="primary", use_container_width=True):
                if not tavily_key:
                    st.warning("‚ö†Ô∏è Tavily API Key √© necess√°ria para enriquecimento completo.")
                
                # Status step-by-step com feedback visual rico
                with st.status("üöÄ Iniciando VerbaFlow...", expanded=True) as status:
                    try:
                        # Step 1: Prepara√ß√£o
                        status.update(label="üîÑ Limpando e preparando texto...", state="running")
                        cleaned_text = clean_text(raw_text)
                        
                        # Step 2: Configura√ß√£o LLM
                        status.update(label="‚öôÔ∏è Configurando LLM (Groq)...", state="running")
                        if "OPENAI_API_KEY" in os.environ:
                            original_openai_key = os.environ.pop("OPENAI_API_KEY", None)
                        
                        selected_model = os.getenv("GROQ_MODEL", "llama-3.1-8b-instant")
                        llm_provider = "Groq"  # Inicializar vari√°vel
                        
                        try:
                            llm = get_llm(model_name=selected_model)
                            llm_provider = "Groq"
                        except Exception as e:
                            error_str = str(e).lower()
                            is_rate_limit = "429" in error_str or "rate limit" in error_str or "rate_limit" in error_str
                            
                            if is_rate_limit:
                                raise ValueError(
                                    f"Rate limit do Groq atingido: {e}\n\n"
                                    "üí° **Solu√ß√µes:**\n"
                                    "1. Troque para modelo menor (llama-3.1-8b-instant) na sidebar - consome ~10x menos tokens\n"
                                    "2. Aguarde o reset do limite (geralmente √† meia-noite UTC)\n"
                                    "3. Fa√ßa upgrade para Dev Tier: https://console.groq.com/settings/billing"
                                )
                            raise
                        
                        # Step 3: Criar agentes
                        status.update(label="ü§ñ Criando agentes especializados...", state="running")
                        analyst = create_analyst_agent(llm)
                        researcher = create_researcher_agent(llm)
                        editor = create_editor_agent(llm)
                        
                        # Step 4: Criar tasks
                        status.update(label="üìã Criando tasks e pipeline...", state="running")
                        # Preparar few-shot examples do hist√≥rico (se dispon√≠vel)
                        few_shot_examples = []
                        if 'execution_history' in st.session_state and st.session_state['execution_history']:
                            for hist in st.session_state['execution_history'][-3:]:  # √öltimos 3
                                category = hist.get('predicted') or hist.get('category')
                                if 'text_sample' in hist and category:
                                    few_shot_examples.append({
                                        'text': hist['text_sample'],
                                        'category': category,
                                        'reasoning': hist.get('reasoning', f"Classificado como {category}")
                                    })
                        
                        task1 = create_classification_task(analyst, cleaned_text, few_shot_examples if few_shot_examples else None)
                        task2 = create_enrichment_task(researcher, task1)
                        task3 = create_reporting_task(editor, task1, task2)
                        
                        crew = Crew(
                            agents=[analyst, researcher, editor],
                            tasks=[task1, task2, task3],
                            process=Process.sequential,
                            verbose=True,
                            tracing=True  # Ativar tracing do CrewAI
                        )
                        
                        # Step 5: Executar Task 1 - Classifica√ß√£o
                        status.update(label="üïµÔ∏è [Task 1/3] Analisando texto com Chain of Thought...", state="running")
                        old_stdout = sys.stdout
                        sys.stdout = StringIO()
                        
                        result = None
                        try:
                            # Executar crew com tracing ativado
                            st.info("üîç **Tracing ativado:** Acompanhe o progresso detalhado do CrewAI...")
                            result = crew.kickoff()
                            
                            # Capturar output do tracing ap√≥s execu√ß√£o
                            output = sys.stdout.getvalue()
                            if output and len(output.strip()) > 0:
                                with st.expander("üìä Detalhes do Tracing (CrewAI)", expanded=False):
                                    st.code(output, language="text")
                        except Exception as crew_error:
                            error_str = str(crew_error)
                            # Verificar se √© rate limit
                            is_rate_limit = (
                                "429" in error_str or 
                                "rate_limit" in error_str.lower() or 
                                "Rate limit" in error_str or
                                "rate limit reached" in error_str.lower()
                            )
                            
                            # Se for rate limit, mostrar mensagem de erro
                            if is_rate_limit:
                                # Extrair tempo de espera se dispon√≠vel
                                wait_time = "algumas horas"
                                if "try again in" in error_str.lower():
                                    import re
                                    time_match = re.search(r'try again in (\d+m\d+\.\d+s)', error_str, re.IGNORECASE)
                                    if time_match:
                                        wait_time = time_match.group(1)
                                
                                # Rate limit atingido - mostrar mensagem de erro
                                st.error("""
                                ## ‚ö†Ô∏è Rate Limit Atingido
                                
                                Voc√™ atingiu o limite di√°rio de tokens do Groq (100,000 tokens/dia no tier gratuito).
                                
                                **üìä Informa√ß√µes:**
                                - Limite: 100,000 tokens/dia (tier gratuito)
                                - Modelo atual: """ + f"{os.getenv('GROQ_MODEL', 'llama-3.1-8b-instant')}" + """
                                - Tempo estimado para reset: """ + wait_time + """
                                
                                **üí° Solu√ß√µes Imediatas:**
                                
                                1. **Trocar para modelo menor:** 
                                   - V√° na sidebar e selecione `llama-3.1-8b-instant`
                                   - Este modelo consome **~10x menos tokens** que o 70b
                                   - Qualidade ainda √© excelente para classifica√ß√£o
                                
                                2. **Aguardar reset:** 
                                   - O limite ser√° resetado automaticamente (geralmente √† meia-noite UTC)
                                   - Tempo estimado: """ + wait_time + """
                                
                                3. **Upgrade para Dev Tier:**
                                   - Limite muito maior (30M tokens/dia)
                                   - Acesso a modelos premium
                                   - https://console.groq.com/settings/billing
                                
                                **üéØ Recomenda√ß√£o:** Use `llama-3.1-8b-instant` como padr√£o - √© r√°pido, eficiente e tem qualidade excelente!
                                """)
                                
                                # Bot√£o para trocar modelo automaticamente
                                if st.button("üîÑ Trocar para llama-3.1-8b-instant agora", type="primary"):
                                    os.environ["GROQ_MODEL"] = "llama-3.1-8b-instant"
                                    st.success("‚úÖ Modelo alterado! Recarregue a p√°gina e tente novamente.")
                                    st.rerun()
                                
                                status.update(label=f"‚ùå Erro: Rate limit", state="error")
                                st.stop()
                            else:
                                # Erro n√£o relacionado a rate limit
                                raise crew_error
                        finally:
                            sys.stdout = old_stdout
                        
                        if result is None:
                            st.error("‚ùå Execu√ß√£o falhou sem resultado")
                            st.stop()
                        
                        status.update(label="‚úÖ An√°lise completa! Processando resultados...", state="complete")
                    
                    except Exception as e:
                        error_str = str(e)
                        status.update(label=f"‚ùå Erro: {str(e)[:50]}...", state="error")
                        st.error(f"‚ùå Erro durante execu√ß√£o: {e}")
                        with st.expander("üîç Detalhes do Erro"):
                            st.exception(e)
                        st.stop()
                
                # Extrair categoria com parsing robusto
                result_str = str(result)
                predicted_category = ""
                classification_data = None
                
                # Tentar parsear JSON estruturado primeiro (m√©todo preferido)
                try:
                    # Procurar por JSON no resultado (pode estar em qualquer lugar do texto)
                    json_patterns = [
                        r'\{[^{}]*"final_category"[^{}]*"confidence"[^{}]*\}',  # JSON com final_category e confidence
                        r'\{[^{}]*"final_category"[^{}]*\}',  # JSON com final_category
                        r'\{.*?"entity_analysis".*?"final_category".*?\}',  # JSON completo
                    ]
                    
                    for pattern in json_patterns:
                        json_match = re.search(pattern, result_str, re.DOTALL | re.IGNORECASE)
                        if json_match:
                            json_str = json_match.group(0)
                            try:
                                data = json.loads(json_str)
                                if 'final_category' in data:
                                    predicted_category = data['final_category']
                                    classification_data = data
                                    break
                            except json.JSONDecodeError:
                                continue
                except Exception:
                    # Se falhar, continuar com parsing tradicional
                    pass
                
                # Fallback: parsing robusto tradicional
                if not predicted_category:
                    predicted_category = extract_category_robust(result_str)
                    
                    # Se n√£o encontrou, tentar buscar no output da task1 diretamente
                    if not predicted_category and hasattr(result, 'tasks_output'):
                        for task_output in result.tasks_output:
                            predicted_category = extract_category_robust(str(task_output))
                            if predicted_category:
                                break
                    
                    # Se ainda n√£o encontrou, buscar no texto completo com padr√µes mais flex√≠veis
                    if not predicted_category:
                        category_pattern = r'\b(' + '|'.join([
                            r'alt\.atheism', r'comp\.graphics', r'comp\.os\.ms-windows\.misc',
                            r'comp\.sys\.ibm\.pc\.hardware', r'comp\.sys\.mac\.hardware', r'comp\.windows\.x',
                            r'misc\.forsale', r'rec\.autos', r'rec\.motorcycles',
                            r'rec\.sport\.baseball', r'rec\.sport\.hockey', r'sci\.crypt',
                            r'sci\.electronics', r'sci\.med', r'sci\.space',
                            r'soc\.religion\.christian', r'talk\.politics\.guns',
                            r'talk\.politics\.mideast', r'talk\.politics\.misc', r'talk\.religion\.misc'
                        ]) + r')\b'
                        match = re.search(category_pattern, result_str, re.IGNORECASE)
                        if match:
                            predicted_category = match.group(1)
                
                # Layout de duas colunas para resultados
                st.markdown("---")
                st.markdown("## üìä Resultados da An√°lise")
                
                col_left, col_right = st.columns([1, 1])
                
                with col_left:
                    st.markdown("### üìÑ Texto Original")
                    # Usando st.text_area que √© mais sem√¢ntico e permite rolagem nativa
                    st.text_area(
                        "Texto Original",
                        raw_text,
                        height=300,
                        disabled=True,
                        label_visibility="collapsed"
                    )

                    st.markdown(f"**üè∑Ô∏è Categoria Real (Ground Truth):**")
                    st.markdown(f'<span class="category-badge">{ground_truth}</span>', unsafe_allow_html=True)
                
                with col_right:
                    st.markdown("### ‚úÖ Valida√ß√£o da Classifica√ß√£o")
                    
                    # Comparar categorias (case-insensitive)
                    is_correct = predicted_category.lower() == ground_truth.lower() if predicted_category else False
                    
                    if is_correct:
                        st.markdown('<div class="success-indicator">‚úÖ Classifica√ß√£o Correta!</div>', unsafe_allow_html=True)
                        st.balloons()
                    else:
                        st.markdown('<div class="error-indicator">‚ùå Classifica√ß√£o Incorreta</div>', unsafe_allow_html=True)
                    
                    # M√©tricas
                    st.metric("Categoria Real", ground_truth)
                    st.metric("Categoria Prevista", predicted_category if predicted_category else "N√£o encontrada")
                
                # Relat√≥rio completo em se√ß√£o expand√≠vel
                st.markdown("---")
                
                # Extrair markdown do relat√≥rio se dispon√≠vel
                report_markdown = None
                try:
                    # Tentar extrair JSON do resultado
                    json_pattern = r'\{[^{}]*"full_report_markdown"[^{}]*\}'
                    json_match = re.search(json_pattern, result_str, re.DOTALL | re.IGNORECASE)
                    if json_match:
                        try:
                            data = json.loads(json_match.group(0))
                            if 'full_report_markdown' in data:
                                report_markdown = data['full_report_markdown']
                        except json.JSONDecodeError:
                            # Tentar buscar JSON completo
                            json_full_pattern = r'\{.*?"full_report_markdown".*?\}'
                            json_full_match = re.search(json_full_pattern, result_str, re.DOTALL | re.IGNORECASE)
                            if json_full_match:
                                try:
                                    data = json.loads(json_full_match.group(0))
                                    if 'full_report_markdown' in data:
                                        report_markdown = data['full_report_markdown']
                                except json.JSONDecodeError:
                                    pass
                except Exception:
                    pass
                
                # Usar HTML customizado para evitar problema de √≠cone
                st.markdown("""
                <details open style="background-color: #1e1e1e; padding: 1rem; border-radius: 8px; margin: 1rem 0; border: 1px solid rgba(255,255,255,0.1);">
                    <summary style="font-weight: 600; font-size: 1.1rem; cursor: pointer; padding: 0.5rem; color: #FFFFFF;">
                        üìã Relat√≥rio Enriquecido Completo
                    </summary>
                    <div style="margin-top: 1rem; padding: 1rem; background-color: #121212; border-radius: 4px; color: #FFFFFF;">
                """, unsafe_allow_html=True)
                
                # Renderizar markdown se dispon√≠vel, sen√£o mostrar resultado completo
                if report_markdown:
                    st.markdown(report_markdown)
                else:
                    st.markdown(result_str)
                
                st.markdown("""
                    </div>
                </details>
                """, unsafe_allow_html=True)
                
                # Salvar resultado na sess√£o e hist√≥rico
                from datetime import datetime
                execution_record = {
                    'timestamp': datetime.now().isoformat(),
                    'ground_truth': ground_truth,
                    'predicted': predicted_category,
                    'is_correct': is_correct,
                    'report': result_str,
                    'text_sample': raw_text[:200],  # Primeiros 200 caracteres
                    'llm_provider': llm_provider if 'llm_provider' in locals() else "Groq",
                    'classification_data': classification_data if 'classification_data' in locals() else None
                }
                
                st.session_state['last_result'] = execution_record
                
                # Adicionar ao hist√≥rico
                if 'execution_history' not in st.session_state:
                    st.session_state['execution_history'] = []
                
                st.session_state['execution_history'].append(execution_record)
                
                # Manter apenas os √∫ltimos N itens
                config = get_config()
                max_items = config.max_history_items
                if len(st.session_state['execution_history']) > max_items:
                    st.session_state['execution_history'] = st.session_state['execution_history'][-max_items:]

else:  # CSV Customizado
    st.subheader("üìä CSV Customizado (6 Classes)")
    
    csv_path = "data/raw/Base_dados_textos_6_classes.csv"
    
    if not os.path.exists(csv_path):
        st.warning(f"‚ö†Ô∏è Arquivo CSV n√£o encontrado em: {csv_path}")
        st.info("Por favor, coloque o arquivo 'Base_dados_textos_6_classes.csv' na pasta data/raw/")
    else:
        df = load_custom_csv(csv_path)
        
        if not df.empty:
            # Assumir que o CSV tem colunas 'texto' e 'categoria' (ou similar)
            # Tentar detectar automaticamente
            text_col = None
            category_col = None
            
            for col in df.columns:
                col_lower = col.lower()
                if 'text' in col_lower or 'texto' in col_lower:
                    text_col = col
                if 'categor' in col_lower or 'class' in col_lower or 'label' in col_lower:
                    category_col = col
            
            if text_col and category_col:
                st.dataframe(df.head(), use_container_width=True)
                
                selected_idx = st.selectbox(
                    "Selecione um registro:",
                    options=range(len(df)),
                    format_func=lambda x: f"Registro {x+1}: {df.iloc[x][category_col]}"
                )
                
                if selected_idx is not None:
                    raw_text = str(df.iloc[selected_idx][text_col])
                    ground_truth = str(df.iloc[selected_idx][category_col])
                    
                    st.markdown("### üìÑ Texto Original")
                    st.text_area("Texto Original", raw_text, height=200, disabled=True, label_visibility="visible")
                    
                    st.markdown(f"### üè∑Ô∏è Categoria Real (Ground Truth)")
                    st.info(f"**{ground_truth}**")
                    
                    if st.button("üöÄ Executar VerbaFlow", type="primary"):
                        # Similar ao fluxo acima, mas adaptado para CSV
                        st.info("Funcionalidade para CSV customizado - implementa√ß√£o similar ao 20 Newsgroups")
            else:
                st.error("‚ùå N√£o foi poss√≠vel detectar automaticamente as colunas 'texto' e 'categoria' no CSV.")
                st.info("Colunas encontradas: " + ", ".join(df.columns.tolist()))
        else:
            st.error("‚ùå Erro ao carregar CSV ou arquivo vazio.")
